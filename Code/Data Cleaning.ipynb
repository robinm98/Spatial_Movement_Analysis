{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Project\n",
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning - Wolf data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/Hebblewhite Alberta-BC Wolves.csv'\n",
    "wolves_data = pd.read_csv(file_path)\n",
    "\n",
    "# Rename the column \"comments\" to \"Pack name\"\n",
    "wolves_data.rename(columns={'comments': 'Pack name'}, inplace=True)\n",
    "\n",
    "# Convert any timestamps to datetime format if they're not already\n",
    "wolves_data['timestamp'] = pd.to_datetime(wolves_data['timestamp'])\n",
    "\n",
    "# Filter the data to include only observations from 2001 to 2011\n",
    "wolves_data = wolves_data[(wolves_data['timestamp'].dt.year >= 2001) & (wolves_data['timestamp'].dt.year <= 2011)]\n",
    "\n",
    "# Add 'individual-id' and 'animal-type' columns\n",
    "wolves_data['individual-id'] = wolves_data['individual-local-identifier']\n",
    "wolves_data['animal-type'] = 'Wolf'\n",
    "\n",
    "# Filter the data to include only the wanted packs\n",
    "packs = [\"Wildhorse\", \"Ranch\", \"Red Deer\", \"Cascade\", \"Bow Valley\"]\n",
    "wolves_data = wolves_data[wolves_data['Pack name'].isin(packs)]\n",
    "\n",
    "# Update the 'Pack name' column for observations with individual-id B065\n",
    "wolves_data.loc[wolves_data['individual-id'] == 'B065', 'Pack name'] = 'Cascade'\n",
    "\n",
    "# Rearrange the columns to match the elk DataFrame\n",
    "wolves_data = wolves_data[['individual-id', 'event-id', 'timestamp', 'location-long', 'location-lat', 'animal-type', 'Pack name']]\n",
    "\n",
    "# Save the cleaned data\n",
    "output_path = '../Data/clean_data_wolf.csv'\n",
    "wolves_data.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the head to verify\n",
    "print(wolves_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning - Elk data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/Ya Ha Tinda elk project, Banff National Park, 2001-2012.csv'\n",
    "elk_data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert any timestamps to datetime format if they're not already\n",
    "elk_data['timestamp'] = pd.to_datetime(elk_data['timestamp'])\n",
    "\n",
    "# Add a new column 'animal-type' with the value 'Elk' for all rows\n",
    "elk_data['animal-type'] = 'Elk'\n",
    "\n",
    "# Rename the individual ID column\n",
    "elk_data['individual-id'] = elk_data['individual-local-identifier']\n",
    "\n",
    "# Filter the DataFrame to include only data from 2001 to 2011\n",
    "elk_data = elk_data[elk_data['timestamp'].dt.year.between(2001, 2011)]\n",
    "\n",
    "# Create the cleaned DataFrame with only the necessary columns\n",
    "elk_data = elk_data[['individual-id','event-id', 'timestamp', 'location-long', 'location-lat', 'animal-type']].copy()\n",
    "\n",
    "# Save the cleaned data\n",
    "output_path = '../Data/clean_data_elk.csv'\n",
    "elk_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(elk_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge clean_data_elk and clean_data_wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'year_month' column to both datasets\n",
    "wolves_data['year_month'] = wolves_data['timestamp'].dt.to_period('M')\n",
    "elk_data['year_month'] = elk_data['timestamp'].dt.to_period('M')\n",
    "\n",
    "# Get the unique year-month periods from wolf data\n",
    "wolf_year_months = set(wolves_data['year_month'].unique())\n",
    "\n",
    "# Filter the elk data to only include observations that match the wolf year-month periods\n",
    "elk_data = elk_data[elk_data['year_month'].isin(wolf_year_months)]\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "combined_data = pd.concat([elk_data, wolves_data], ignore_index=True)\n",
    "\n",
    "# Drop year_month column as we use only timestamp column\n",
    "combined_data = combined_data.drop(columns=['year_month'])\n",
    "\n",
    "# Save the combined data\n",
    "combined_data_path = '../Data/merged_data.csv'\n",
    "combined_data.to_csv(combined_data_path, index=False)\n",
    "\n",
    "print(combined_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance travelled between each observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the timestamp column is a datetime object and sort by 'individual-id' and 'timestamp'\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.sort_values(by=['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Filter out the wolf data\n",
    "wolf_data = data[data['animal-type'] == 'Wolf'].copy()\n",
    "\n",
    "# Initialize an empty list to store distances\n",
    "distances = []\n",
    "\n",
    "# Loop through the DataFrame by each wolf\n",
    "for wolf_id in wolf_data['individual-id'].unique():\n",
    "    # Get the specific wolf's data\n",
    "    wolf_observations = wolf_data[wolf_data['individual-id'] == wolf_id].sort_values('timestamp')\n",
    "    \n",
    "    # Start with a distance of 0.0 for the first observation of each wolf\n",
    "    individual_distances = [0.0]\n",
    "    \n",
    "    # Compute the distance between each consecutive observation\n",
    "    for i in range(1, len(wolf_observations)):\n",
    "        # Get the current and previous observation's location\n",
    "        current_location = (wolf_observations.iloc[i]['location-lat'], wolf_observations.iloc[i]['location-long'])\n",
    "        previous_location = (wolf_observations.iloc[i - 1]['location-lat'], wolf_observations.iloc[i - 1]['location-long'])\n",
    "        \n",
    "        # Calculate the distance and append to the individual_distances list\n",
    "        distance = geodesic(previous_location, current_location).kilometers\n",
    "        individual_distances.append(distance)\n",
    "\n",
    "    # Extend the main distances list with the individual distances\n",
    "    distances.extend(individual_distances)\n",
    "\n",
    "# Add the distances as a new column to the wolf_data DataFrame\n",
    "wolf_data['distance_traveled'] = distances\n",
    "\n",
    "# merge this information back into the main DataFrame\n",
    "data = data.drop(columns=['distance_traveled'], errors='ignore')  # Drop the column if it already exists\n",
    "data = data.merge(wolf_data[['individual-id', 'timestamp', 'distance_traveled']], on=['individual-id', 'timestamp'], how='left')\n",
    "\n",
    "data.to_csv('../Data/merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add proximity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate elk and wolf data based on 'animal-type'\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "wolf_data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Perform K-Means clustering on elk data\n",
    "elk_coords = elk_data[['location-lat', 'location-long']]\n",
    "kmeans = KMeans(n_clusters=11, random_state=0).fit(elk_coords)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Initialize list to store proximity data\n",
    "proximity_values = []\n",
    "\n",
    "# Calculate proximity for each wolf observation\n",
    "for index, wolf in wolf_data.iterrows():\n",
    "    nearest_distance = float('inf')\n",
    "    for centroid in centroids:\n",
    "        distance = geodesic((wolf['location-lat'], wolf['location-long']), centroid).kilometers\n",
    "        if distance < nearest_distance:\n",
    "            nearest_distance = distance\n",
    "\n",
    "    # Calculate proximity metric and store it with index to ensure alignment\n",
    "    proximity_value = 1 / (nearest_distance + 1)  # Inverse of distance to model closeness\n",
    "    proximity_values.append({'index': index, 'Proximity': proximity_value})\n",
    "\n",
    "# Create a DataFrame from the proximity values\n",
    "proximity_df = pd.DataFrame(proximity_values).set_index('index')\n",
    "\n",
    "# Join the proximity data back to the wolf data using the index\n",
    "wolf_data = wolf_data.join(proximity_df, on=wolf_data.index, rsuffix='_proximity')\n",
    "\n",
    "# Update the main data DataFrame with the new proximity values for wolves\n",
    "data.loc[wolf_data.index, 'Proximity'] = wolf_data['Proximity']\n",
    "\n",
    "# Save the updated DataFrame\n",
    "data.to_csv('../Data/merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set index as int \n",
    "Indexing was altered in the merging process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'event-id' column to integer type\n",
    "data['event-id'] = data['event-id'].astype(int)\n",
    "\n",
    "data.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
