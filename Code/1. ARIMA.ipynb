{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Project\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for stationnarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Perform ADF test on a given time series\n",
    "def perform_adf_test(series):\n",
    "    result = adfuller(series, autolag='AIC')  \n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "    \n",
    "for wolf_id, group in data.groupby('individual-id'):\n",
    "    print(f'Performing ADF Test on Wolf {wolf_id}')\n",
    "    print('Latitude:')\n",
    "    perform_adf_test(group['location-lat'])\n",
    "    print('\\nLongitude:')\n",
    "    perform_adf_test(group['location-long'])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv('../Data/merged_data.csv')\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Filter for 'Wolf'\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Loop over each wolf's data\n",
    "for wolf_id, group in data.groupby('individual-id'):\n",
    "    split_index = int(len(group) * 0.8)\n",
    "    train_data = group.iloc[:split_index]\n",
    "    test_data = group.iloc[split_index:]\n",
    "\n",
    "    # Fit ARIMA model on the training data for latitude and longitude\n",
    "    model_lat = auto_arima(train_data['location-lat'], seasonal=False, stepwise=True, max_p=2, max_q=2, d=0, suppress_warnings=True)\n",
    "    model_long = auto_arima(train_data['location-long'], seasonal=False, stepwise=True, max_p=2, max_q=2, d=0, suppress_warnings=True)\n",
    "    \n",
    "    # Predict on the training set to assess training accuracy\n",
    "    train_preds_lat = model_lat.predict(n_periods=len(train_data))\n",
    "    train_preds_long = model_long.predict(n_periods=len(train_data))\n",
    "\n",
    "    # Predict on the test set\n",
    "    test_preds_lat = model_lat.predict(n_periods=len(test_data))\n",
    "    test_preds_long = model_long.predict(n_periods=len(test_data))\n",
    "\n",
    "    # Compute accuracy metrics for training\n",
    "    train_mae_lat = mean_absolute_error(train_data['location-lat'], train_preds_lat)\n",
    "    train_rmse_lat = np.sqrt(mean_squared_error(train_data['location-lat'], train_preds_lat))\n",
    "    train_mae_long = mean_absolute_error(train_data['location-long'], train_preds_long)\n",
    "    train_rmse_long = np.sqrt(mean_squared_error(train_data['location-long'], train_preds_long))\n",
    "\n",
    "    # Compute accuracy metrics for testing\n",
    "    test_mae_lat = mean_absolute_error(test_data['location-lat'], test_preds_lat)\n",
    "    test_rmse_lat = np.sqrt(mean_squared_error(test_data['location-lat'], test_preds_lat))\n",
    "    test_mae_long = mean_absolute_error(test_data['location-long'], test_preds_long)\n",
    "    test_rmse_long = np.sqrt(mean_squared_error(test_data['location-long'], test_preds_long))\n",
    "\n",
    "    # Store results\n",
    "    results[wolf_id] = {\n",
    "        'training_accuracy': {'MAE_lat': train_mae_lat, 'RMSE_lat': train_rmse_lat, 'MAE_long': train_mae_long, 'RMSE_long': train_rmse_long},\n",
    "        'test_accuracy': {'MAE_lat': test_mae_lat, 'RMSE_lat': test_rmse_lat, 'MAE_long': test_mae_long, 'RMSE_long': test_rmse_long},\n",
    "        'test_predictions': (test_preds_lat, test_preds_long),\n",
    "        'actual_test_data': (test_data['location-lat'].values, test_data['location-long'].values)\n",
    "    }\n",
    "\n",
    "# Display results for each wolf\n",
    "for wolf_id, info in results.items():\n",
    "    print(f\"Wolf ID: {wolf_id}\")\n",
    "    print(\"Training Accuracy:\", info['training_accuracy'])\n",
    "    print(\"Test Accuracy:\", info['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Function to create a map for a single wolf\n",
    "def create_wolf_map(wolf_data, test_preds_lat, test_preds_long, wolf_id):\n",
    "    # Starting point for the map\n",
    "    start_lat = wolf_data['location-lat'].iloc[0]\n",
    "    start_long = wolf_data['location-long'].iloc[0]\n",
    "    wolf_map = folium.Map(location=[start_lat, start_long], zoom_start=8)\n",
    "\n",
    "    # Split the data into training and testing\n",
    "    split_index = int(len(wolf_data) * 0.8)\n",
    "    train_data = wolf_data.iloc[:split_index]\n",
    "    test_data = wolf_data.iloc[split_index:]\n",
    "\n",
    "    # Define the HTML code for a green cross\n",
    "    html_green_cross = '''\n",
    "    <div style=\"position: relative; width: 8px; height: 8px;\">\n",
    "        <div style=\"position: absolute; top: 50%; left: 0; transform: translate(0%, -50%); width: 100%; height: 2px; background-color: purple;\"></div>\n",
    "        <div style=\"position: absolute; top: 0; left: 50%; transform: translate(-50%, 0%); width: 2px; height: 100%; background-color: purple;\"></div>\n",
    "    </div>\n",
    "    '''\n",
    "    \n",
    "    # Add training data points and draw lines between them\n",
    "    train_points = [(row['location-lat'], row['location-long']) for idx, row in train_data.iterrows()]\n",
    "    folium.PolyLine(train_points, color=\"blue\", weight=2.5, opacity=1).add_to(wolf_map)\n",
    "    for point in train_points:\n",
    "        folium.CircleMarker(\n",
    "            location=point,\n",
    "            radius=3,\n",
    "            color='blue',\n",
    "            fill=True,\n",
    "            fill_color='blue',\n",
    "            popup='Train'\n",
    "        ).add_to(wolf_map)\n",
    "\n",
    "    # Add test data points and draw lines between them\n",
    "    test_points = [(row['location-lat'], row['location-long']) for idx, row in test_data.iterrows()]\n",
    "    folium.PolyLine(test_points, color=\"green\", weight=2.5, opacity=1).add_to(wolf_map)\n",
    "    for point in test_points:\n",
    "        folium.CircleMarker(\n",
    "            location=point,\n",
    "            radius=3,\n",
    "            color='green',\n",
    "            fill=True,\n",
    "            fill_color='green',\n",
    "            popup='Test'\n",
    "        ).add_to(wolf_map)\n",
    "\n",
    "    # Mark the first test observation with a green cross\n",
    "    folium.Marker(\n",
    "        location=test_points[0],\n",
    "        icon=folium.DivIcon(html=html_green_cross),\n",
    "        popup='First Test Observation'\n",
    "    ).add_to(wolf_map)\n",
    "\n",
    "    # Add prediction points and draw lines between them\n",
    "    prediction_points = list(zip(test_preds_lat, test_preds_long))\n",
    "    folium.PolyLine(prediction_points, color=\"red\", weight=2.5, opacity=1).add_to(wolf_map)\n",
    "    for idx, point in enumerate(prediction_points):\n",
    "        folium.CircleMarker(\n",
    "            location=point,\n",
    "            radius=3,\n",
    "            color='red',\n",
    "            fill=True,\n",
    "            fill_color='red',\n",
    "            popup=f'Predicted: {test_data.index[idx]}'\n",
    "        ).add_to(wolf_map)\n",
    "\n",
    "    # Save the map\n",
    "    wolf_map.save(f'../Visualisation/ARIMA/wolf_{wolf_id}_map.html')\n",
    "\n",
    "# Iterate through each wolf and create a map\n",
    "for wolf_id, info in results.items():\n",
    "    test_preds_lat = info['test_predictions'][0]\n",
    "    test_preds_long = info['test_predictions'][1]\n",
    "    wolf_data = data[data['individual-id'] == wolf_id]\n",
    "    create_wolf_map(wolf_data, test_preds_lat, test_preds_long, wolf_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA accuracy for each wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# Haversine function definition\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points \n",
    "    on the Earth (specified in decimal degrees).\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "# Initialize results dictionary outside of the loop\n",
    "results = {}\n",
    "\n",
    "# Loop over each wolf's data\n",
    "for wolf_id, group in data.groupby('individual-id'):\n",
    "    split_index = int(len(group) * 0.8)\n",
    "    test_data = group.iloc[split_index:]\n",
    "\n",
    "    # Calculate the Haversine distance for each prediction in the test set\n",
    "    distances = [\n",
    "        haversine(pred_lon, pred_lat, act_lon, act_lat)\n",
    "        for pred_lon, pred_lat, act_lon, act_lat in zip(test_preds_long, test_preds_lat, test_data['location-long'], test_data['location-lat'])\n",
    "    ]\n",
    "\n",
    "    # Calculate mean, median, MAE, and RMSE for the Haversine distances\n",
    "    mean_distance_error = np.mean(distances)\n",
    "    median_distance_error = np.median(distances)\n",
    "    \n",
    "    # Store results including Haversine distances\n",
    "    results[wolf_id] = {\n",
    "        'test_accuracy': {\n",
    "            'MAE_lat': test_mae_lat,  \n",
    "            'RMSE_lat': test_rmse_lat,\n",
    "            'MAE_long': test_mae_long,\n",
    "            'RMSE_long': test_rmse_long\n",
    "        },\n",
    "        'haversine_accuracy': {\n",
    "            'Mean_Haversine_Distance': mean_distance_error,\n",
    "            'Median_Haversine_Distance': median_distance_error\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Print the results for each wolf\n",
    "for wolf_id, info in results.items():\n",
    "    print(f\"Wolf ID: {wolf_id}\")\n",
    "    print('MAE_lat:', info['test_accuracy']['MAE_lat'])\n",
    "    print('RMSE_lat:', info['test_accuracy']['RMSE_lat'])\n",
    "    print('MAE_long:', info['test_accuracy']['MAE_long'])\n",
    "    print('RMSE_long:', info['test_accuracy']['RMSE_long'])\n",
    "    print('Mean_Haversine_Distance:', info['haversine_accuracy']['Mean_Haversine_Distance'])\n",
    "    print('Median_Haversine_Distance:', info['haversine_accuracy']['Median_Haversine_Distance'])\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to accumulate the metrics\n",
    "total_mae_lat = 0\n",
    "total_rmse_lat = 0\n",
    "total_mae_long = 0\n",
    "total_rmse_long = 0\n",
    "total_mean_haversine_distance = 0\n",
    "total_median_haversine_distance = 0\n",
    "num_wolves = len(results)\n",
    "\n",
    "# Loop over each wolf's results\n",
    "for wolf_id, info in results.items():\n",
    "    # Accumulate individual metrics\n",
    "    total_mae_lat += info['test_accuracy']['MAE_lat']\n",
    "    total_rmse_lat += info['test_accuracy']['RMSE_lat']\n",
    "    total_mae_long += info['test_accuracy']['MAE_long']\n",
    "    total_rmse_long += info['test_accuracy']['RMSE_long']\n",
    "    total_mean_haversine_distance += info['haversine_accuracy']['Mean_Haversine_Distance']\n",
    "    total_median_haversine_distance += info['haversine_accuracy']['Median_Haversine_Distance']\n",
    "\n",
    "# Calculate average metrics\n",
    "average_mae_lat = total_mae_lat / num_wolves\n",
    "average_rmse_lat = total_rmse_lat / num_wolves\n",
    "average_mae_long = total_mae_long / num_wolves\n",
    "average_rmse_long = total_rmse_long / num_wolves\n",
    "average_mean_haversine_distance = total_mean_haversine_distance / num_wolves\n",
    "average_median_haversine_distance = total_median_haversine_distance / num_wolves\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics for All Wolves:\")\n",
    "print(f\"Average MAE Latitude: {average_mae_lat:.4f}\")\n",
    "print(f\"Average RMSE Latitude: {average_rmse_lat:.4f}\")\n",
    "print(f\"Average MAE Longitude: {average_mae_long:.4f}\")\n",
    "print(f\"Average RMSE Longitude: {average_rmse_long:.4f}\")\n",
    "print(f\"Average Mean Haversine Distance: {average_mean_haversine_distance:.2f} km\")\n",
    "print(f\"Average Median Haversine Distance: {average_median_haversine_distance:.2f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for wolf_id, group in data.groupby('individual-id'):\n",
    "\n",
    "    # Convert results dictionary to a DataFrame for easier CSV saving\n",
    "    results_df = pd.DataFrame([results[wolf_id]])\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results_csv_path = f'../Results/ARIMA results/results_{wolf_id}.csv'\n",
    "    results_df.to_csv(results_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
