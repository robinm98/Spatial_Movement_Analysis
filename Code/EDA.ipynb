{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA project\n",
    "## EDA\n",
    "## EDA - Elk\n",
    "\n",
    "##### Elk description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "\n",
    "# Total number of unique elk\n",
    "total_elk = elk_data['individual-id'].nunique()\n",
    "\n",
    "# Number of observations per elk\n",
    "observations_per_elk = elk_data['individual-id'].value_counts()\n",
    "\n",
    "# Timeframe of observations\n",
    "earliest_observation = elk_data['timestamp'].min()\n",
    "latest_observation = elk_data['timestamp'].max()\n",
    "\n",
    "# Location spread\n",
    "min_latitude = elk_data['location-lat'].min()\n",
    "max_latitude = elk_data['location-lat'].max()\n",
    "min_longitude = elk_data['location-long'].min()\n",
    "max_longitude = elk_data['location-long'].max()\n",
    "\n",
    "\n",
    "# Observations per year (or month)\n",
    "elk_data['timestamp'] = pd.to_datetime(elk_data['timestamp'])\n",
    "observations_per_year = elk_data['timestamp'].dt.year.value_counts()\n",
    "observations_per_month = elk_data['timestamp'].dt.to_period('M').value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total number of elk: {total_elk}\")\n",
    "print(\"Number of observations per elk:\")\n",
    "print(observations_per_elk)\n",
    "print(f\"Timeframe of observations: {earliest_observation} to {latest_observation}\")\n",
    "print(f\"Location spread: Latitudes from {min_latitude} to {max_latitude}, Longitudes from {min_longitude} to {max_longitude}\")\n",
    "print(\"Observations per year:\")\n",
    "print(observations_per_year)\n",
    "print(\"Observations per month:\")\n",
    "print(observations_per_month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total of number of obersvations in merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "data = data[data['animal-type'] == 'Elk']\n",
    "\n",
    "# Calculate the total number of observations\n",
    "total_observations = data.shape[0]\n",
    "total_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Timeframe of observation per elk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "\n",
    "# Convert the 'timestamp' column to datetime\n",
    "elk_data['timestamp'] = pd.to_datetime(elk_data['timestamp'])\n",
    "\n",
    "# Group by 'individual-local-identifier' and get the first and last timestamp\n",
    "first_last_obs = elk_data.groupby('individual-id')['timestamp'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "first_last_obs.rename(columns={'min': 'First Observation', 'max': 'Last Observation'}, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(first_last_obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance travelled by each elk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees).\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371  # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "\n",
    "# Ensure the data is sorted by individual and timestamp\n",
    "elk_data.sort_values(by=['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Calculate the distance traveled by each wolf\n",
    "elk_data['shifted_long'] = elk_data.groupby('individual-id')['location-long'].shift(-1)\n",
    "elk_data['shifted_lat'] = elk_data.groupby('individual-id')['location-lat'].shift(-1)\n",
    "elk_data['distance'] = elk_data.apply(lambda row: haversine(row['location-long'], row['location-lat'], row['shifted_long'], row['shifted_lat']) if not np.isnan(row['shifted_long']) else 0, axis=1)\n",
    "\n",
    "# Summing up the distances for each wolf and include the pack name\n",
    "total_distance_by_elk = elk_data.groupby(['individual-id'])['distance'].sum().reset_index(name='total_distance')\n",
    "\n",
    "# Print the result with the pack name as the last column\n",
    "print(total_distance_by_elk[['individual-id', 'total_distance']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance travelled by each elk per month on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation - ELk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "\n",
    "# Generate a base map\n",
    "# Determine the center of your map - this example uses the mean of the latitudes and longitudes\n",
    "map_center = [elk_data['location-lat'].mean(), elk_data['location-long'].mean()]\n",
    "heat_map_elk = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Add a heatmap to the map\n",
    "heat_data = [[row['location-lat'], row['location-long']] for index, row in elk_data.iterrows()]\n",
    "HeatMap(heat_data, radius=15, blur=15).add_to(heat_map_elk)\n",
    "\n",
    "# Save the map\n",
    "output_map_path = '../Visualisation/EDA/Heat_map_elk.html'\n",
    "heat_map_elk.save(output_map_path)\n",
    "\n",
    "heat_map_elk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movement map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations and sort by individual and timestamp\n",
    "elk_data = data[data['animal-type'] == 'Elk'].copy()\n",
    "elk_data['timestamp'] = pd.to_datetime(elk_data['timestamp'])\n",
    "elk_data.sort_values(by=['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Initialize a base map\n",
    "map_center = [elk_data['location-lat'].mean(), elk_data['location-long'].mean()]\n",
    "movement_map_elk = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Prepare a color for each elk\n",
    "unique_ids = elk_data['individual-id'].unique()\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_ids)))\n",
    "\n",
    "# Define the HTML code for a red cross\n",
    "html_green_cross = '''\n",
    "<div style=\"position: relative; width: 8px; height: 8px;\">\n",
    "    <div style=\"position: absolute; top: 50%; left: 0; transform: translate(0%, -50%); width: 100%; height: 2px; background-color: green;\"></div>\n",
    "    <div style=\"position: absolute; top: 0; left: 50%; transform: translate(-50%, 0%); width: 2px; height: 100%; background-color: green;\"></div>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "html_red_cross = '''\n",
    "<div style=\"position: relative; width: 8px; height: 8px;\">\n",
    "    <div style=\"position: absolute; top: 50%; left: 0; transform: translate(0%, -50%); width: 100%; height: 2px; background-color: red;\"></div>\n",
    "    <div style=\"position: absolute; top: 0; left: 50%; transform: translate(-50%, 0%); width: 2px; height: 100%; background-color: red;\"></div>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "# Iterate through each elk and plot their movements\n",
    "for idx, elk_id in enumerate(elk_data['individual-id'].unique()):\n",
    "    elk = elk_data[elk_data['individual-id'] == elk_id]\n",
    "    \n",
    "    # Create lines for each movement\n",
    "    locations = elk[['location-lat', 'location-long']].values.tolist()\n",
    "    if len(locations) > 1:  # Need at least two points to create a line\n",
    "        # Add lines for movement\n",
    "        folium.PolyLine(locations, color='grey', weight=2, opacity=0.5).add_to(movement_map_elk)\n",
    "        \n",
    "        # Add crosses at the first and last observation\n",
    "        first_observation = locations[0]\n",
    "        last_observation = locations[-1]\n",
    "        folium.Marker(location=first_observation, icon=folium.DivIcon(html=html_green_cross)).add_to(movement_map_elk)\n",
    "        folium.Marker(location=last_observation, icon=folium.DivIcon(html=html_red_cross)).add_to(movement_map_elk)\n",
    "\n",
    "# Save the map\n",
    "output_map_path = '../Visualisation/EDA/Movement_map_elk.html'\n",
    "movement_map_elk.save(output_map_path)\n",
    "\n",
    "movement_map_elk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elk clustering\n",
    "##### Cluster map\n",
    "K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# Filter for wolf observations\n",
    "data = data[data['animal-type'] == 'Elk']\n",
    "elk_coords = data[['location-lat', 'location-long']]\n",
    "\n",
    "# Calculate WCSS for a range of k values\n",
    "wcss = []\n",
    "for i in range(1, 20):  # Test for k from 1 to 19\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(elk_coords)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 20), wcss, marker='o')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')  # Within-cluster sum of squares\n",
    "plt.xticks(range(1, 20))\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "elk_coords = elk_data[['location-lat', 'location-long']]\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=15, random_state=0).fit(elk_coords)\n",
    "elk_data['cluster'] = kmeans.labels_\n",
    "\n",
    "# Calculate cluster centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Create map\n",
    "map_center = [elk_data['location-lat'].mean(), elk_data['location-long'].mean()]\n",
    "cluster_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Create heatmap data from the elk coordinates\n",
    "heat_data = elk_coords.values.tolist()\n",
    "\n",
    "# Add heatmap layer\n",
    "HeatMap(heat_data, radius=15, blur=15, min_opacity=0.5).add_to(cluster_map)\n",
    "\n",
    "# Plot cluster centroids\n",
    "for centroid in centroids:\n",
    "    folium.CircleMarker(\n",
    "        location=(centroid[0], centroid[1]),\n",
    "        radius=10,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.6,\n",
    "        popup='Cluster Center'\n",
    "    ).add_to(cluster_map)\n",
    "\n",
    "# Save the map\n",
    "output_map_path = '../Visualisation/EDA/cluster_kmeans_map_elk.html'\n",
    "cluster_map.save(output_map_path)\n",
    "\n",
    "cluster_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Elk']\n",
    "elk_coords = data[['location-lat', 'location-long']]\n",
    "\n",
    "# Ensure there are no missing values\n",
    "elk_coords.dropna(inplace=True)\n",
    "\n",
    "# Calculate BIC for a range of number of components\n",
    "bic = []\n",
    "for i in range(1, 20):  # Adjust the range as needed\n",
    "    gmm = GaussianMixture(n_components=i, random_state=0)\n",
    "    gmm.fit(elk_coords)\n",
    "    bic.append(gmm.bic(elk_coords))\n",
    "\n",
    "# Plot the elbow graph for BIC\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 20), bic, marker='o')\n",
    "plt.title('Elbow Method For Optimal Number of GMM Components')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('BIC')\n",
    "plt.xticks(range(1, 20))\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "elk_coords = elk_data[['location-lat', 'location-long']]\n",
    "\n",
    "# Perform GMM clustering\n",
    "gmm = GaussianMixture(n_components=15, random_state=0).fit(elk_coords)\n",
    "elk_data['cluster'] = gmm.predict(elk_coords)\n",
    "\n",
    "# Calculate centroids (mean of clusters)\n",
    "centroids = elk_data.groupby('cluster').mean()[['location-lat', 'location-long']]\n",
    "\n",
    "# Create map\n",
    "map_center = [elk_data['location-lat'].mean(), elk_data['location-long'].mean()]\n",
    "cluster_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Create heatmap data from the elk coordinates\n",
    "heat_data = elk_coords.values.tolist()\n",
    "\n",
    "# Add heatmap layer\n",
    "HeatMap(heat_data, radius=15, blur=15, min_opacity=0.5).add_to(cluster_map)\n",
    "\n",
    "# Plot centroids\n",
    "for idx, row in centroids.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=(row['location-lat'], row['location-long']),\n",
    "        radius=10,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.6\n",
    "    ).add_to(cluster_map)\n",
    "\n",
    "\n",
    "cluster_map.save('../Visualisation/EDA/cluster_gmm_map_elk.html')\n",
    "cluster_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "elk_coords = elk_data[['location-lat', 'location-long']]\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.1, min_samples=10).fit(elk_coords)\n",
    "elk_data['cluster'] = dbscan.labels_\n",
    "\n",
    "# Filter out noise points\n",
    "filtered_elk_data = elk_data[elk_data['cluster'] != -1]\n",
    "\n",
    "# Calculate centroids (mean of clusters)\n",
    "centroids = filtered_elk_data.groupby('cluster').mean()[['location-lat', 'location-long']]\n",
    "\n",
    "# Create map\n",
    "map_center = [elk_data['location-lat'].mean(), elk_data['location-long'].mean()]\n",
    "cluster_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Create heatmap data from the elk coordinates\n",
    "heat_data = elk_coords.values.tolist()\n",
    "\n",
    "# Add heatmap layer\n",
    "HeatMap(heat_data, radius=15, blur=15, min_opacity=0.5).add_to(cluster_map)\n",
    "\n",
    "# Plot centroids\n",
    "for idx, row in centroids.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=(row['location-lat'], row['location-long']),\n",
    "        radius=10,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.6\n",
    "    ).add_to(cluster_map)\n",
    "\n",
    "# Save the map\n",
    "cluster_map.save('../Visualisation/EDA/cluster_dbscan_map_elk.html')\n",
    "\n",
    "cluster_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import folium\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations and subsample every 100th observation\n",
    "elk_data = data[data['animal-type'] == 'Elk'].iloc[::100, :]\n",
    "elk_coords = elk_data[['location-lat', 'location-long']]\n",
    "\n",
    "# Normalize the coordinates\n",
    "scaler = StandardScaler()\n",
    "elk_coords_scaled = scaler.fit_transform(elk_coords)\n",
    "\n",
    "# Use KDTree for efficient distance computation\n",
    "tree = KDTree(elk_coords_scaled, leaf_size=40)\n",
    "\n",
    "# DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=10, algorithm='auto', leaf_size=40)\n",
    "elk_data['cluster'] = dbscan.fit_predict(tree.data)\n",
    "\n",
    "# Create map\n",
    "map_center = [elk_data['location-lat'].mean(), elk_data['location-long'].mean()]\n",
    "cluster_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Plot elk locations with cluster color\n",
    "for idx, row in elk_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=(row['location-lat'], row['location-long']),\n",
    "        radius=5,\n",
    "        color='blue' if row['cluster'] == -1 else 'green',\n",
    "        fill=True,\n",
    "        fill_color='blue' if row['cluster'] == -1 else 'green',\n",
    "        fill_opacity=0.7\n",
    "    ).add_to(cluster_map)\n",
    "\n",
    "# Save the map\n",
    "cluster_map.save('/Users/robin/Library/Mobile Documents/com~apple~CloudDocs/UNIL/HEC cours/Master/MA 2/Advandced Data Analysis/Project/Visualisation/cluster_map_elk.html')\n",
    "cluster_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clustering performances :\n",
    "--> K-means better than GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture  # Corrected import\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for elk observations\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "elk_coords = elk_data[['location-lat', 'location-long']]\n",
    "\n",
    "# K-Means clustering\n",
    "kmeans = KMeans(n_clusters=11, random_state=0).fit(elk_coords)\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Gaussian Mixture clustering\n",
    "gmm = GaussianMixture(n_components=11, random_state=0).fit(elk_coords)\n",
    "gmm_labels = gmm.predict(elk_coords)\n",
    "\n",
    "# Evaluate clustering performance\n",
    "\n",
    "calinski_kmeans = calinski_harabasz_score(elk_coords, kmeans_labels)\n",
    "calinski_gmm = calinski_harabasz_score(elk_coords, gmm_labels)\n",
    "\n",
    "davies_kmeans = davies_bouldin_score(elk_coords, kmeans_labels)\n",
    "davies_gmm = davies_bouldin_score(elk_coords, gmm_labels)\n",
    "\n",
    "print(\"Calinski-Harabasz Scores: K-Means:\", calinski_kmeans, \"GMM:\", calinski_gmm)\n",
    "print(\"Davies-Bouldin Scores: K-Means:\", davies_kmeans, \"GMM:\", davies_gmm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wolf per pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Group by 'Pack name' and aggregate the unique 'individual-id's within each group\n",
    "pack_wolves = data.groupby('Pack name')['individual-id'].unique()\n",
    "\n",
    "# Count the number of wolves in each pack\n",
    "pack_counts = data.groupby('Pack name')['individual-id'].nunique()\n",
    "\n",
    "# Create a descriptive text for each pack including the count and IDs of wolves\n",
    "pack_descriptions = pack_wolves.apply(lambda x: f\"{len(x)} wolves: {' '.join(x)}\").to_dict()\n",
    "\n",
    "# Display the number of wolves and their IDs in each pack\n",
    "for pack, ids in pack_descriptions.items():\n",
    "    count = pack_counts[pack]\n",
    "    print(f\"{pack} - {ids}\")\n",
    "\n",
    "# B065 changed pack from Ranch to Cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Timeframe of observation per wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Convert the 'timestamp' column to datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Group by 'individual-local-identifier' and get the first and last timestamp\n",
    "first_last_obs = data.groupby('individual-id')['timestamp'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "first_last_obs.rename(columns={'min': 'First Observation', 'max': 'Last Observation'}, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(first_last_obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of observations per wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Count the number of observations per individual wolf\n",
    "observation_counts = data['individual-id'].value_counts()\n",
    "\n",
    "# Convert to DataFrame for better readability if desired\n",
    "observation_counts_df = observation_counts.reset_index()\n",
    "observation_counts_df.columns = ['individual-id', 'observation_count']\n",
    "\n",
    "# Display the counts\n",
    "print(observation_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance travelled by each wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees).\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371  # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Ensure the data is sorted by individual and timestamp\n",
    "data.sort_values(by=['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Calculate the distance traveled by each wolf\n",
    "data['shifted_long'] = data.groupby('individual-id')['location-long'].shift(-1)\n",
    "data['shifted_lat'] = data.groupby('individual-id')['location-lat'].shift(-1)\n",
    "data['distance'] = data.apply(lambda row: haversine(row['location-long'], row['location-lat'], row['shifted_long'], row['shifted_lat']) if not np.isnan(row['shifted_long']) else 0, axis=1)\n",
    "\n",
    "# Summing up the distances for each wolf and include the pack name\n",
    "total_distance_by_wolf = data.groupby(['individual-id', 'Pack name'])['distance'].sum().reset_index(name='total_distance')\n",
    "\n",
    "# Order by pack name\n",
    "total_distance_by_wolf = total_distance_by_wolf.sort_values(by='Pack name')\n",
    "\n",
    "# Print the result with the pack name as the last column\n",
    "print(total_distance_by_wolf[['individual-id', 'total_distance', 'Pack name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance travelled on average per month per wolf !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Area covered - MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Filter out future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiPoint\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    data, \n",
    "    geometry=gpd.points_from_xy(data['location-long'], data['location-lat'])\n",
    ")\n",
    "\n",
    "# Set the coordinate reference system to WGS84 (latitude/longitude)\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Convert to a projected CRS to measure area in square kilometers (e.g., World Equidistant Cylindrical)\n",
    "gdf.to_crs(epsg=4087, inplace=True)  # This CRS allows for area calculations\n",
    "\n",
    "# Initialize an empty DataFrame to store the area for each wolf\n",
    "wolf_areas = pd.DataFrame(columns=['individual-id', 'area_km2'])\n",
    "\n",
    "# Calculate MCP and area for each wolf\n",
    "for wolf_id in gdf['individual-id'].unique():\n",
    "    # Extract points for the current wolf\n",
    "    points = gdf[gdf['individual-id'] == wolf_id]['geometry']\n",
    "    \n",
    "    # Create a MultiPoint object from the wolf's points\n",
    "    multipoint = MultiPoint([point for point in points])\n",
    "    \n",
    "    # Create the MCP (convex hull of the points)\n",
    "    mcp = multipoint.convex_hull\n",
    "    \n",
    "    # Calculate the area in square kilometers and store it\n",
    "    area_km2 = mcp.area / 1e6  # Convert from m² to km²\n",
    "    wolf_areas = wolf_areas.append({'individual-id': wolf_id, 'area_km2': area_km2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Calculate the average area covered per year for each wolf\n",
    "wolf_areas['average_area_per_year_km2'] = wolf_areas['area_km2'] / 10\n",
    "\n",
    "# Display the area covered by each wolf\n",
    "print(wolf_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance traveled depending on the period of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert timestamps to datetime and sort by individual and timestamp\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "# Filter out the wolf data\n",
    "wolf_data = data[data['animal-type'] == 'Wolf'].copy()\n",
    "\n",
    "# Create a new column for the part of day based on the hour of the timestamp\n",
    "wolf_data['part_of_day'] = pd.cut(\n",
    "    wolf_data['timestamp'].dt.hour,\n",
    "    bins=[0, 6, 12, 18, 24],\n",
    "    include_lowest=True,\n",
    "    labels=['Night', 'Morning', 'Day', 'Evening']\n",
    ")\n",
    "\n",
    "# Group by part of day and sum the distances\n",
    "distance_by_time = wolf_data.groupby('part_of_day')['distance_traveled'].sum()\n",
    "\n",
    "# Create a bar plot\n",
    "distance_by_time.plot(kind='bar', figsize=(10, 6), color='skyblue')\n",
    "plt.title('Distance Traveled by Wolves at Different Times of the Day')\n",
    "plt.xlabel('Part of the Day')\n",
    "plt.ylabel('Total Distance Traveled (km)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust the plot to ensure everything fits without overlapping\n",
    "plt.show()\n",
    "\n",
    "# Save the plot as an image\n",
    "output_plot_path = '../Visualisation/EDA/distance_by_time.png'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packs cohesion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation within a pack - eg. Ranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for wolf observations\n",
    "wolf_data = data[data['animal-type'] == 'Wolf'].copy()\n",
    "\n",
    "# Ensure the timestamp is a datetime object and sort the data\n",
    "wolf_data['timestamp'] = pd.to_datetime(wolf_data['timestamp'])\n",
    "wolf_data.sort_values(by=['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Function to calculate movement vectors for each wolf\n",
    "def calculate_movement_vectors(df):\n",
    "    df['lat_change'] = df['location-lat'].diff()\n",
    "    df['long_change'] = df['location-long'].diff()\n",
    "    return df\n",
    "\n",
    "# Apply the function to calculate movement vectors for each wolf\n",
    "wolf_data = wolf_data.groupby('individual-id').apply(calculate_movement_vectors)\n",
    "\n",
    "# Drop the first observation since the diff will result in NaN\n",
    "wolf_data = wolf_data.dropna(subset=['lat_change', 'long_change'])\n",
    "\n",
    "# Select a single pack to analyze\n",
    "specific_pack_name = 'Ranch'\n",
    "single_pack_data = wolf_data[wolf_data['Pack name'] == specific_pack_name]\n",
    "\n",
    "# Prepare the DataFrame for correlation calculation of latitude changes\n",
    "correlation_data_lat = single_pack_data.pivot_table(index='timestamp', columns='individual-id', values='lat_change').dropna()\n",
    "\n",
    "# Prepare the DataFrame for correlation calculation of longitude changes\n",
    "correlation_data_long = single_pack_data.pivot_table(index='timestamp', columns='individual-id', values='long_change').dropna()\n",
    "\n",
    "# Compute the correlation matrix for latitude changes\n",
    "correlation_matrix_lat = correlation_data_lat.corr()\n",
    "\n",
    "# Compute the correlation matrix for longitude changes\n",
    "correlation_matrix_long = correlation_data_long.corr()\n",
    "\n",
    "# Plotting the correlation matrix for latitude changes\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix_lat, annot=True, fmt=\".2f\", cmap=\"BrBG\", center=0, cbar_kws={'label': 'Correlation Coefficient'})\n",
    "plt.title(f'Latitude Change Correlation Matrix within {specific_pack_name}')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the correlation matrix for longitude changes\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix_long, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, cbar_kws={'label': 'Correlation Coefficient'})\n",
    "plt.title(f'Longitude Change Correlation Matrix within {specific_pack_name}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation - Wolf\n",
    "##### Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for wolf observations\n",
    "wolf_data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Generate a base map\n",
    "# Determine the center of your map - this example uses the mean of the latitudes and longitudes\n",
    "map_center = [wolf_data['location-lat'].mean(), wolf_data['location-long'].mean()]\n",
    "heat_map_wolf = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Add a heatmap to the map\n",
    "heat_data = [[row['location-lat'], row['location-long']] for index, row in wolf_data.iterrows()]\n",
    "HeatMap(heat_data, radius=15, blur=15).add_to(heat_map_wolf)\n",
    "\n",
    "# Save the map\n",
    "output_map_path = '../Visualisation/EDA/Heat_map_wolf.html'\n",
    "heat_map_wolf.save(output_map_path)\n",
    "\n",
    "heat_map_wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movement map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter for wolf observations and sort by individual and timestamp\n",
    "wolf_data = data[data['animal-type'] == 'Wolf'].copy()\n",
    "wolf_data['timestamp'] = pd.to_datetime(wolf_data['timestamp'])\n",
    "wolf_data.sort_values(by=['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Define pack colors\n",
    "pack_colors = {\n",
    "    'Wildhorse': 'red',\n",
    "    'Ranch': 'blue',\n",
    "    'Red Deer': 'purple',\n",
    "    'Cascade': 'olive',\n",
    "    'Bow Valley': 'orange'\n",
    "}\n",
    "\n",
    "# Initialize a base map\n",
    "map_center = [wolf_data['location-lat'].mean(), wolf_data['location-long'].mean()]\n",
    "movement_map_wolf = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Iterate through each wolf and plot their movements\n",
    "for pack in pack_colors:\n",
    "    pack_wolves = wolf_data[wolf_data['Pack name'] == pack]\n",
    "    unique_ids = pack_wolves['individual-id'].unique()\n",
    "    color = pack_colors[pack]\n",
    "    \n",
    "    for wolf_id in unique_ids:\n",
    "        wolf = pack_wolves[pack_wolves['individual-id'] == wolf_id]\n",
    "        \n",
    "        # Create lines for each movement\n",
    "        locations = wolf[['location-lat', 'location-long']].values.tolist()\n",
    "        if len(locations) > 1:  # Need at least two points to create a line\n",
    "            # Add lines for movement\n",
    "            folium.PolyLine(locations, color=color, weight=2, opacity=0.4).add_to(movement_map_wolf)\n",
    "            \n",
    "            # Add crosses at the first and last observation\n",
    "            first_observation = locations[0]\n",
    "            last_observation = locations[-1]\n",
    "            html_green_cross = f'''\n",
    "                <div style=\"position: relative; width: 10px; height: 10px;\">\n",
    "                    <div style=\"position: absolute; top: 50%; left: 0; transform: translate(0%, -50%); width: 100%; height: 2px; background-color: green;\"></div>\n",
    "                    <div style=\"position: absolute; top: 0; left: 50%; transform: translate(-50%, 0%); width: 2px; height: 100%; background-color: green;\"></div>\n",
    "                </div>\n",
    "            '''\n",
    "            html_red_cross = f'''\n",
    "                <div style=\"position: relative; width: 10px; height: 10px;\">\n",
    "                    <div style=\"position: absolute; top: 50%; left: 0; transform: translate(0%, -50%); width: 100%; height: 2px; background-color: red;\"></div>\n",
    "                    <div style=\"position: absolute; top: 0; left: 50%; transform: translate(-50%, 0%); width: 2px; height: 100%; background-color: red;\"></div>\n",
    "                </div>\n",
    "            '''\n",
    "            folium.Marker(location=first_observation, icon=folium.DivIcon(html=html_green_cross)).add_to(movement_map_wolf)\n",
    "            folium.Marker(location=last_observation, icon=folium.DivIcon(html=html_red_cross)).add_to(movement_map_wolf)\n",
    "\n",
    "# Save the map\n",
    "output_map_path = '../Visualisation/EDA/Movement_map_wolf.html'\n",
    "movement_map_wolf.save(output_map_path)\n",
    "\n",
    "movement_map_wolf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wolf time series analysis\n",
    "#### ACF/PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Assuming the data has columns 'timestamp', 'individual-id', 'location-lat', 'location-long'\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.sort_values(['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Plot ACF and PACF for each wolf's latitude and longitude\n",
    "for wolf_id, group in data.groupby('individual-id'):\n",
    "    group.set_index('timestamp', inplace=True)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    "    # ACF and PACF for latitude\n",
    "    plot_acf(group['location-lat'], ax=axes[0][0], title=f'Wolf {wolf_id} - ACF of Latitude')\n",
    "    plot_pacf(group['location-lat'], ax=axes[0][1], title=f'Wolf {wolf_id} - PACF of Latitude')\n",
    "\n",
    "    # ACF and PACF for longitude\n",
    "    plot_acf(group['location-long'], ax=axes[1][0], title=f'Wolf {wolf_id} - ACF of Longitude')\n",
    "    plot_pacf(group['location-long'], ax=axes[1][1], title=f'Wolf {wolf_id} - PACF of Longitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stationnarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Perform ADF test on a given time series\n",
    "def perform_adf_test(series):\n",
    "    result = adfuller(series, autolag='AIC')  # 'AIC' will choose the best lag based on information criterion\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "    \n",
    "for wolf_id, group in data.groupby('individual-id'):\n",
    "    print(f'Performing ADF Test on Wolf {wolf_id}')\n",
    "    print('Latitude:')\n",
    "    perform_adf_test(group['location-lat'])\n",
    "    print('\\nLongitude:')\n",
    "    perform_adf_test(group['location-long'])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lat/Long analysis over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Assuming the data has columns 'timestamp', 'individual-id', 'location-lat', 'location-long'\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.sort_values(['individual-id', 'timestamp'], inplace=True)\n",
    "\n",
    "# Plotting\n",
    "num_wolves = len(data['individual-id'].unique())\n",
    "fig, axes = plt.subplots(nrows=num_wolves, ncols=2, figsize=(15, 6 * num_wolves), squeeze=False)\n",
    "\n",
    "for idx, (wolf_id, group) in enumerate(data.groupby('individual-id')):\n",
    "    group.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    group['location-lat'].plot(ax=axes[idx][0], title=f\"Wolf {wolf_id} - Latitude\")\n",
    "    axes[idx][0].set_ylabel('Latitude')\n",
    "    axes[idx][0].grid(True)\n",
    "\n",
    "    group['location-long'].plot(ax=axes[idx][1], title=f\"Wolf {wolf_id} - Longitude\")\n",
    "    axes[idx][1].set_ylabel('Longitude')\n",
    "    axes[idx][1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Wolf & Elk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wolf and elk movement correlation !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement map wolf & elk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter and sort data for elk and wolf\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "elk_data = data[data['animal-type'] == 'Elk'].sort_values(by=['individual-id', 'timestamp'])\n",
    "wolf_data = data[data['animal-type'] == 'Wolf'].sort_values(by=['individual-id', 'timestamp'])\n",
    "\n",
    "# Initialize a base map\n",
    "map_center = [(elk_data['location-lat'].mean() + wolf_data['location-lat'].mean()) / 2,\n",
    "              (elk_data['location-long'].mean() + wolf_data['location-long'].mean()) / 2]\n",
    "movement_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Function to add lines to the map\n",
    "def add_movement_lines(animal_data, line_color, map_obj):\n",
    "    for animal_id in animal_data['individual-id'].unique():\n",
    "        animal = animal_data[animal_data['individual-id'] == animal_id]\n",
    "        locations = animal[['location-lat', 'location-long']].values.tolist()\n",
    "        if len(locations) > 1:  # Need at least two points to create a line\n",
    "            folium.PolyLine(locations, color=line_color, weight=2, opacity=0.3).add_to(map_obj)\n",
    "\n",
    "# Add movement lines for wolves in red\n",
    "add_movement_lines(wolf_data, 'red', movement_map)\n",
    "\n",
    "# Add movement lines for elk in green\n",
    "add_movement_lines(elk_data, 'green', movement_map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "output_html_path = '../Visualisation/EDA/Movement_map_elk_wolf.html'\n",
    "movement_map.save(output_html_path)\n",
    "\n",
    "movement_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With ranch pack in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter and sort data for elk and wolf\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "elk_data = data[data['animal-type'] == 'Elk'].sort_values(by=['individual-id', 'timestamp'])\n",
    "wolf_data = data[(data['animal-type'] == 'Wolf') & (data['Pack name'] != 'Ranch')].sort_values(by=['individual-id', 'timestamp'])\n",
    "ranch_wolf_data = data[(data['animal-type'] == 'Wolf') & (data['Pack name'] == 'Ranch')].sort_values(by=['individual-id', 'timestamp'])\n",
    "\n",
    "# Initialize a base map\n",
    "map_center = [(elk_data['location-lat'].mean() + wolf_data['location-lat'].mean()) / 2,\n",
    "              (elk_data['location-long'].mean() + wolf_data['location-long'].mean()) / 2]\n",
    "movement_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Function to add lines to the map\n",
    "def add_movement_lines(animal_data, line_color, map_obj):\n",
    "    for animal_id in animal_data['individual-id'].unique():\n",
    "        animal = animal_data[animal_data['individual-id'] == animal_id]\n",
    "        locations = animal[['location-lat', 'location-long']].values.tolist()\n",
    "        if len(locations) > 1:  # Need at least two points to create a line\n",
    "            folium.PolyLine(locations, color=line_color, weight=2, opacity=0.5).add_to(map_obj)\n",
    "\n",
    "# Add movement lines for wolves (excluding Ranch pack) in red\n",
    "add_movement_lines(wolf_data, 'red', movement_map)\n",
    "\n",
    "# Add movement lines for Ranch wolves in blue\n",
    "add_movement_lines(ranch_wolf_data, 'blue', movement_map)\n",
    "\n",
    "# Add movement lines for elk in green\n",
    "add_movement_lines(elk_data, 'green', movement_map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "output_html_path = '../Visualisation/EDA/Movement_map_elk_ranch_wolf.html'\n",
    "movement_map.save(output_html_path)\n",
    "\n",
    "movement_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximity analysis\n",
    "##### Compute proximity metric from nearest clusters using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate elk and wolf data based on 'animal-type'\n",
    "elk_data = data[data['animal-type'] == 'Elk']\n",
    "wolf_data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Perform K-Means clustering on elk data\n",
    "elk_coords = elk_data[['location-lat', 'location-long']]\n",
    "kmeans = KMeans(n_clusters=11, random_state=0).fit(elk_coords)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Initialize list to store proximity data\n",
    "proximity_values = []\n",
    "\n",
    "# Calculate proximity for each wolf observation\n",
    "for index, wolf in wolf_data.iterrows():\n",
    "    nearest_distance = float('inf')\n",
    "    for centroid in centroids:\n",
    "        distance = geodesic((wolf['location-lat'], wolf['location-long']), centroid).kilometers\n",
    "        if distance < nearest_distance:\n",
    "            nearest_distance = distance\n",
    "\n",
    "    # Calculate proximity metric and store it with index to ensure alignment\n",
    "    proximity_value = 1 / (nearest_distance + 1)  # Inverse of distance to model closeness\n",
    "    proximity_values.append({'index': index, 'Proximity': proximity_value})\n",
    "\n",
    "# Create a DataFrame from the proximity values\n",
    "proximity_df = pd.DataFrame(proximity_values).set_index('index')\n",
    "\n",
    "# Join the proximity data back to the wolf data using the index\n",
    "wolf_data = wolf_data.join(proximity_df, on=wolf_data.index, rsuffix='_proximity')\n",
    "\n",
    "# Update the main data DataFrame with the new proximity values for wolves\n",
    "data.loc[wolf_data.index, 'Proximity'] = wolf_data['Proximity']\n",
    "\n",
    "# Save the updated DataFrame\n",
    "data.to_csv('../Data/EDA/merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wolves with highest proximity\n",
    "\n",
    "d = 0.8 = 0.25 km <br>\n",
    "d = 0.5 = 1 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter wolf_data based on proximity higher than 0.8\n",
    "high_proximity_wolves = wolf_data[wolf_data['Proximity'] > 0.5]\n",
    "\n",
    "# Get the unique individual IDs and pack names of the wolves with high proximity\n",
    "unique_high_proximity_wolves_info = high_proximity_wolves[['individual-id', 'Pack name']].drop_duplicates()\n",
    "\n",
    "print(\"Unique individual IDs and pack names of wolves with proximity higher than 0.5:\")\n",
    "print(unique_high_proximity_wolves_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proximity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "from folium.plugins import HeatMap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../Data/merged_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "wolf_data = data[data['animal-type'] == 'Wolf']\n",
    "\n",
    "# Create a map centered around the average location\n",
    "map_center = [wolf_data['location-lat'].mean(), wolf_data['location-long'].mean()]\n",
    "proximity_map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Define the color mapping function\n",
    "def color_proximity(value):\n",
    "    norm = plt.Normalize(wolf_data['Proximity'].min(), wolf_data['Proximity'].max())\n",
    "    cmap = plt.cm.viridis\n",
    "    rgb = cmap(norm(value))  # RGB from RGBA\n",
    "    return mcolors.to_hex(rgb[:3])  # Convert to hexadecimal\n",
    "\n",
    "# Add markers for each wolf location colored by proximity\n",
    "for index, row in wolf_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=(row['location-lat'], row['location-long']),\n",
    "        radius=5,  \n",
    "        color=color_proximity(row['Proximity']),  # Convert proximity to a color\n",
    "        fill=True,\n",
    "        fill_color=color_proximity(row['Proximity']),\n",
    "        fill_opacity=0.7\n",
    "    ).add_to(proximity_map)\n",
    "\n",
    "\n",
    "# Save the map to an HTML file\n",
    "output_html_path = '../Visualisation/EDA/proximity_map.html'\n",
    "proximity_map.save(output_html_path)\n",
    "\n",
    "proximity_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
